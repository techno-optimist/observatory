"""
Real-Time Emergent Communication Monitor

The critical missing piece for AI safety applications. This module monitors
communication streams in real-time, detecting:

1. REGIME SHIFTS: When communication crosses phase boundaries
   (NATURAL → TECHNICAL → COMPRESSED → OPAQUE)

2. COORDINATION DRIFT: When manifold position changes significantly
   relative to baseline

3. PROTOCOL OSSIFICATION: When communication becomes rigid/repetitive
   (variance → 0)

4. MODE COLLAPSE: When coordination diversity decreases
   (all messages cluster in one region)

5. LEGIBILITY DECAY: When human interpretability drops below threshold

Architecture:
- Sliding window analysis
- Exponential moving averages for smooth tracking
- Alert thresholds with configurable sensitivity
- Event streaming for integration with monitoring systems

Usage:
    monitor = EmergentCommunicationMonitor()

    for message in communication_stream:
        event = monitor.process(message)
        if event.alert:
            handle_alert(event)
"""

import numpy as np
from typing import List, Dict, Optional, Tuple, Iterator, Callable, Any
from dataclasses import dataclass, field
from enum import Enum
from collections import deque
import time
import logging
import json

# Import from sibling modules
from .hierarchical_coordinates import (
    extract_hierarchical_coordinate,
    HierarchicalCoordinate,
    extract_features,
)
from .academic_statistics import (
    fisher_rao_distance,
    hellinger_distance,
    detect_phase_transitions,
    bootstrap_ci,
)

logger = logging.getLogger(__name__)


# =============================================================================
# ENUMS AND DATA CLASSES
# =============================================================================

class CommunicationRegime(Enum):
    """Communication legibility regimes."""
    NATURAL = "natural"           # Full human language, legibility > 0.8
    TECHNICAL = "technical"       # Domain jargon, 0.5 < legibility <= 0.8
    COMPRESSED = "compressed"     # Telegraphic, 0.2 < legibility <= 0.5
    OPAQUE = "opaque"             # Emergent/encoded, legibility <= 0.2
    UNKNOWN = "unknown"


class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"           # Noteworthy but not concerning
    WARNING = "warning"     # Potential issue, worth monitoring
    CRITICAL = "critical"   # Significant deviation, requires attention
    EMERGENCY = "emergency" # Severe anomaly, immediate action needed


class AlertType(Enum):
    """Types of alerts the monitor can generate."""
    REGIME_SHIFT = "regime_shift"
    COORDINATION_DRIFT = "coordination_drift"
    OSSIFICATION = "ossification"
    MODE_COLLAPSE = "mode_collapse"
    LEGIBILITY_DECAY = "legibility_decay"
    VELOCITY_SPIKE = "velocity_spike"
    CENTROID_DRIFT = "centroid_drift"


@dataclass
class MonitoringEvent:
    """Event generated by the monitor for each processed message."""

    timestamp: float
    message_index: int

    # Current state
    coordinates: np.ndarray
    regime: CommunicationRegime
    legibility: float

    # Derived metrics
    velocity: float              # Rate of change in manifold
    variance: float              # Coordination space variance
    centroid_distance: float     # Distance from baseline centroid

    # Alert information
    alert: bool = False
    alert_type: Optional[AlertType] = None
    alert_severity: Optional[AlertSeverity] = None
    alert_message: Optional[str] = None

    # Raw message (optional, for debugging)
    raw_message: Optional[str] = None

    def to_dict(self) -> dict:
        return {
            "timestamp": self.timestamp,
            "message_index": self.message_index,
            "coordinates": self.coordinates.tolist() if isinstance(self.coordinates, np.ndarray) else self.coordinates,
            "regime": self.regime.value,
            "legibility": self.legibility,
            "velocity": self.velocity,
            "variance": self.variance,
            "centroid_distance": self.centroid_distance,
            "alert": self.alert,
            "alert_type": self.alert_type.value if self.alert_type else None,
            "alert_severity": self.alert_severity.value if self.alert_severity else None,
            "alert_message": self.alert_message,
        }

    def to_json(self) -> str:
        return json.dumps(self.to_dict())


@dataclass
class MonitorState:
    """Internal state of the monitor."""

    # Historical data
    coordinates_history: deque = field(default_factory=lambda: deque(maxlen=1000))
    legibility_history: deque = field(default_factory=lambda: deque(maxlen=1000))
    regime_history: deque = field(default_factory=lambda: deque(maxlen=1000))

    # Baseline (established during calibration)
    baseline_centroid: Optional[np.ndarray] = None
    baseline_variance: Optional[float] = None
    baseline_regime: Optional[CommunicationRegime] = None

    # Exponential moving averages
    ema_coordinates: Optional[np.ndarray] = None
    ema_variance: Optional[float] = None
    ema_velocity: Optional[float] = None

    # Counters
    messages_processed: int = 0
    alerts_generated: int = 0
    regime_shifts: int = 0

    # Last values for delta calculation
    last_coordinates: Optional[np.ndarray] = None
    last_regime: Optional[CommunicationRegime] = None


@dataclass
class MonitorConfig:
    """Configuration for the monitor."""

    # Window sizes
    calibration_window: int = 50      # Messages to establish baseline
    analysis_window: int = 20         # Sliding window for current analysis

    # EMA parameters
    ema_alpha: float = 0.1            # Smoothing factor (higher = more responsive)

    # Legibility thresholds (for regime classification)
    legibility_natural: float = 0.8
    legibility_technical: float = 0.5
    legibility_compressed: float = 0.2

    # Alert thresholds
    drift_threshold_warning: float = 1.0     # Centroid distance
    drift_threshold_critical: float = 2.0
    velocity_threshold_warning: float = 0.5   # Change rate
    velocity_threshold_critical: float = 1.0
    variance_ratio_ossification: float = 0.2  # Current/baseline ratio
    mode_collapse_threshold: float = 0.3      # Min variance for health
    legibility_decay_threshold: float = 0.3   # Drop triggers alert

    # Minimum messages before alerting
    min_messages_for_alerts: int = 10


# =============================================================================
# LEGIBILITY COMPUTATION
# =============================================================================

def compute_legibility(text: str) -> float:
    """
    Compute legibility score for a message.

    Legibility measures how interpretable a message is to humans.
    Score ranges from 0 (opaque) to 1 (natural language).

    Factors:
    - Word recognition rate
    - Grammar pattern matches
    - Character entropy
    - Structure regularity
    """
    if not text or len(text.strip()) == 0:
        return 0.0

    # Extract linguistic features
    features = extract_features(text)

    # Word count
    words = text.split()
    word_count = len(words)

    if word_count == 0:
        return 0.0

    # Factor 1: Grammar pattern recognition
    total_pattern_matches = sum(features.values())
    pattern_density = min(total_pattern_matches / (word_count + 1), 1.0)

    # Factor 2: Character-level analysis
    # Natural language has predictable character distributions
    char_counts = {}
    for c in text.lower():
        char_counts[c] = char_counts.get(c, 0) + 1

    total_chars = len(text)
    if total_chars > 0:
        # Check for letter dominance (vs symbols)
        letter_count = sum(1 for c in text.lower() if c.isalpha())
        letter_ratio = letter_count / total_chars

        # Check for space ratio (natural text has ~15-20% spaces)
        space_ratio = text.count(' ') / total_chars
        natural_space = 1.0 - abs(space_ratio - 0.17) * 5  # Penalize deviation
        natural_space = max(0, min(1, natural_space))
    else:
        letter_ratio = 0.0
        natural_space = 0.0

    # Factor 3: Word length distribution
    if words:
        avg_word_length = sum(len(w) for w in words) / len(words)
        # Natural English words average ~4-5 characters
        length_score = 1.0 - abs(avg_word_length - 4.5) / 10
        length_score = max(0, min(1, length_score))
    else:
        length_score = 0.0

    # Factor 4: First-person/pronoun presence (indicates natural communication)
    pronoun_features = features.get("first_person_singular", 0) + \
                       features.get("first_person_plural", 0) + \
                       features.get("second_person", 0)
    pronoun_score = min(pronoun_features / (word_count / 10 + 1), 1.0)

    # Combine factors with weights
    legibility = (
        0.3 * pattern_density +
        0.2 * letter_ratio +
        0.2 * natural_space +
        0.15 * length_score +
        0.15 * pronoun_score
    )

    return max(0.0, min(1.0, legibility))


def classify_regime(legibility: float, config: MonitorConfig) -> CommunicationRegime:
    """Classify communication regime based on legibility score."""
    if legibility > config.legibility_natural:
        return CommunicationRegime.NATURAL
    elif legibility > config.legibility_technical:
        return CommunicationRegime.TECHNICAL
    elif legibility > config.legibility_compressed:
        return CommunicationRegime.COMPRESSED
    else:
        return CommunicationRegime.OPAQUE


# =============================================================================
# MAIN MONITOR CLASS
# =============================================================================

class EmergentCommunicationMonitor:
    """
    Real-time monitor for emergent communication patterns.

    Processes a stream of messages and detects:
    - Regime shifts (natural → opaque)
    - Coordination drift
    - Protocol ossification
    - Mode collapse
    - Legibility decay

    Usage:
        monitor = EmergentCommunicationMonitor()

        # Calibrate with baseline communication
        for msg in baseline_messages:
            monitor.calibrate(msg)

        # Monitor live stream
        for msg in live_stream:
            event = monitor.process(msg)
            if event.alert:
                handle_alert(event)
    """

    def __init__(self, config: Optional[MonitorConfig] = None):
        self.config = config or MonitorConfig()
        self.state = MonitorState()
        self._calibrated = False
        self._alert_callbacks: List[Callable[[MonitoringEvent], None]] = []

    def register_alert_callback(self, callback: Callable[[MonitoringEvent], None]):
        """Register a callback for alerts."""
        self._alert_callbacks.append(callback)

    def calibrate(self, message: str) -> bool:
        """
        Add a message to the calibration baseline.

        Returns True when calibration is complete.
        """
        # Extract coordinates
        coord = extract_hierarchical_coordinate(message)
        coords_array = coord.core.to_array()

        # Compute legibility
        legibility = compute_legibility(message)
        regime = classify_regime(legibility, self.config)

        # Add to history
        self.state.coordinates_history.append(coords_array)
        self.state.legibility_history.append(legibility)
        self.state.regime_history.append(regime)
        self.state.messages_processed += 1

        # Check if calibration complete
        if len(self.state.coordinates_history) >= self.config.calibration_window:
            self._finalize_calibration()
            return True

        return False

    def _finalize_calibration(self):
        """Compute baseline statistics from calibration data."""
        coords_array = np.array(list(self.state.coordinates_history))

        # Baseline centroid
        self.state.baseline_centroid = coords_array.mean(axis=0)

        # Baseline variance
        self.state.baseline_variance = coords_array.var()

        # Most common regime
        from collections import Counter
        regime_counts = Counter(self.state.regime_history)
        self.state.baseline_regime = regime_counts.most_common(1)[0][0]

        # Initialize EMAs
        self.state.ema_coordinates = self.state.baseline_centroid.copy()
        self.state.ema_variance = self.state.baseline_variance
        self.state.ema_velocity = 0.0

        self._calibrated = True
        logger.info(f"Monitor calibrated with {len(self.state.coordinates_history)} messages")
        logger.info(f"  Baseline centroid: {self.state.baseline_centroid}")
        logger.info(f"  Baseline variance: {self.state.baseline_variance:.4f}")
        logger.info(f"  Baseline regime: {self.state.baseline_regime.value}")

    def process(self, message: str) -> MonitoringEvent:
        """
        Process a message and return monitoring event.

        This is the main entry point for real-time monitoring.
        """
        timestamp = time.time()

        # Extract coordinates
        coord = extract_hierarchical_coordinate(message)
        coords_array = coord.core.to_array()

        # Compute legibility
        legibility = compute_legibility(message)
        regime = classify_regime(legibility, self.config)

        # Update history
        self.state.coordinates_history.append(coords_array)
        self.state.legibility_history.append(legibility)
        self.state.regime_history.append(regime)
        self.state.messages_processed += 1

        # Compute metrics
        velocity = self._compute_velocity(coords_array)
        variance = self._compute_current_variance()
        centroid_distance = self._compute_centroid_distance(coords_array)

        # Update EMAs
        self._update_emas(coords_array, variance, velocity)

        # Check for alerts
        alert, alert_type, alert_severity, alert_message = self._check_alerts(
            coords_array, regime, legibility, velocity, variance, centroid_distance
        )

        # Track regime shifts
        if self.state.last_regime and regime != self.state.last_regime:
            self.state.regime_shifts += 1

        # Update last values
        self.state.last_coordinates = coords_array
        self.state.last_regime = regime

        # Create event
        event = MonitoringEvent(
            timestamp=timestamp,
            message_index=self.state.messages_processed,
            coordinates=coords_array,
            regime=regime,
            legibility=legibility,
            velocity=velocity,
            variance=variance,
            centroid_distance=centroid_distance,
            alert=alert,
            alert_type=alert_type,
            alert_severity=alert_severity,
            alert_message=alert_message,
            raw_message=message[:100] if message else None
        )

        # Fire callbacks
        if alert:
            self.state.alerts_generated += 1
            for callback in self._alert_callbacks:
                try:
                    callback(event)
                except Exception as e:
                    logger.error(f"Alert callback error: {e}")

        return event

    def _compute_velocity(self, coords: np.ndarray) -> float:
        """Compute rate of change in manifold position."""
        if self.state.last_coordinates is None:
            return 0.0

        distance = np.linalg.norm(coords - self.state.last_coordinates)
        return distance

    def _compute_current_variance(self) -> float:
        """Compute variance over recent window."""
        if len(self.state.coordinates_history) < 2:
            return 0.0

        window = min(self.config.analysis_window, len(self.state.coordinates_history))
        recent = list(self.state.coordinates_history)[-window:]
        return np.array(recent).var()

    def _compute_centroid_distance(self, coords: np.ndarray) -> float:
        """Compute distance from baseline centroid."""
        if self.state.baseline_centroid is None:
            return 0.0

        return np.linalg.norm(coords - self.state.baseline_centroid)

    def _update_emas(self, coords: np.ndarray, variance: float, velocity: float):
        """Update exponential moving averages."""
        alpha = self.config.ema_alpha

        if self.state.ema_coordinates is not None:
            self.state.ema_coordinates = alpha * coords + (1 - alpha) * self.state.ema_coordinates
        else:
            self.state.ema_coordinates = coords

        if self.state.ema_variance is not None:
            self.state.ema_variance = alpha * variance + (1 - alpha) * self.state.ema_variance
        else:
            self.state.ema_variance = variance

        if self.state.ema_velocity is not None:
            self.state.ema_velocity = alpha * velocity + (1 - alpha) * self.state.ema_velocity
        else:
            self.state.ema_velocity = velocity

    def _check_alerts(
        self,
        coords: np.ndarray,
        regime: CommunicationRegime,
        legibility: float,
        velocity: float,
        variance: float,
        centroid_distance: float
    ) -> Tuple[bool, Optional[AlertType], Optional[AlertSeverity], Optional[str]]:
        """Check for alert conditions."""

        # Skip if not enough messages
        if self.state.messages_processed < self.config.min_messages_for_alerts:
            return False, None, None, None

        # 1. REGIME SHIFT: Transition to more opaque regime
        if self.state.last_regime and regime != self.state.last_regime:
            regime_order = {
                CommunicationRegime.NATURAL: 0,
                CommunicationRegime.TECHNICAL: 1,
                CommunicationRegime.COMPRESSED: 2,
                CommunicationRegime.OPAQUE: 3,
            }
            old_order = regime_order.get(self.state.last_regime, 0)
            new_order = regime_order.get(regime, 0)

            if new_order > old_order:
                severity = AlertSeverity.WARNING if new_order - old_order == 1 else AlertSeverity.CRITICAL
                return True, AlertType.REGIME_SHIFT, severity, \
                    f"Regime shift: {self.state.last_regime.value} → {regime.value}"

        # 2. COORDINATION DRIFT: Large centroid distance
        if centroid_distance > self.config.drift_threshold_critical:
            return True, AlertType.COORDINATION_DRIFT, AlertSeverity.CRITICAL, \
                f"Critical coordination drift: distance={centroid_distance:.3f}"
        elif centroid_distance > self.config.drift_threshold_warning:
            return True, AlertType.COORDINATION_DRIFT, AlertSeverity.WARNING, \
                f"Coordination drift detected: distance={centroid_distance:.3f}"

        # 3. VELOCITY SPIKE: Sudden large change
        if velocity > self.config.velocity_threshold_critical:
            return True, AlertType.VELOCITY_SPIKE, AlertSeverity.CRITICAL, \
                f"Velocity spike: {velocity:.3f}"
        elif velocity > self.config.velocity_threshold_warning:
            return True, AlertType.VELOCITY_SPIKE, AlertSeverity.WARNING, \
                f"Elevated velocity: {velocity:.3f}"

        # 4. OSSIFICATION: Variance dropping below threshold
        if self.state.baseline_variance and self.state.baseline_variance > 0:
            variance_ratio = variance / self.state.baseline_variance
            if variance_ratio < self.config.variance_ratio_ossification:
                return True, AlertType.OSSIFICATION, AlertSeverity.WARNING, \
                    f"Protocol ossification detected: variance ratio={variance_ratio:.3f}"

        # 5. MODE COLLAPSE: Very low variance
        if variance < self.config.mode_collapse_threshold:
            return True, AlertType.MODE_COLLAPSE, AlertSeverity.WARNING, \
                f"Possible mode collapse: variance={variance:.4f}"

        # 6. LEGIBILITY DECAY: Significant drop in legibility
        if len(self.state.legibility_history) >= 2:
            recent_legibility = list(self.state.legibility_history)[-self.config.analysis_window:]
            if len(recent_legibility) >= 2:
                legibility_drop = recent_legibility[0] - legibility
                if legibility_drop > self.config.legibility_decay_threshold:
                    return True, AlertType.LEGIBILITY_DECAY, AlertSeverity.WARNING, \
                        f"Legibility decay: dropped by {legibility_drop:.3f}"

        return False, None, None, None

    def get_status(self) -> Dict[str, Any]:
        """Get current monitor status."""
        return {
            "calibrated": self._calibrated,
            "messages_processed": self.state.messages_processed,
            "alerts_generated": self.state.alerts_generated,
            "regime_shifts": self.state.regime_shifts,
            "current_regime": self.state.last_regime.value if self.state.last_regime else None,
            "baseline_variance": self.state.baseline_variance,
            "ema_variance": self.state.ema_variance,
            "ema_velocity": self.state.ema_velocity,
        }

    def get_trajectory(self, last_n: int = 100) -> np.ndarray:
        """Get recent trajectory through manifold."""
        n = min(last_n, len(self.state.coordinates_history))
        return np.array(list(self.state.coordinates_history)[-n:])

    def reset(self):
        """Reset monitor state."""
        self.state = MonitorState()
        self._calibrated = False


# =============================================================================
# STREAMING HELPERS
# =============================================================================

def monitor_stream(
    messages: Iterator[str],
    config: Optional[MonitorConfig] = None,
    calibration_messages: Optional[List[str]] = None
) -> Iterator[MonitoringEvent]:
    """
    Monitor a stream of messages, yielding events.

    Usage:
        for event in monitor_stream(message_iterator):
            if event.alert:
                print(f"ALERT: {event.alert_message}")
    """
    monitor = EmergentCommunicationMonitor(config)

    # Calibration phase
    if calibration_messages:
        for msg in calibration_messages:
            monitor.calibrate(msg)
    else:
        # Use first N messages for calibration
        calibration_count = 0
        target = (config or MonitorConfig()).calibration_window

        for msg in messages:
            if monitor.calibrate(msg):
                break
            calibration_count += 1
            if calibration_count >= target:
                break

    # Monitoring phase
    for msg in messages:
        yield monitor.process(msg)


def batch_analyze(
    messages: List[str],
    config: Optional[MonitorConfig] = None
) -> Dict[str, Any]:
    """
    Analyze a batch of messages and return summary statistics.

    Returns:
        Dictionary with trajectory, alerts, regime distribution, etc.
    """
    config = config or MonitorConfig()
    monitor = EmergentCommunicationMonitor(config)

    events = []

    # Process all messages
    for i, msg in enumerate(messages):
        if i < config.calibration_window:
            monitor.calibrate(msg)
        else:
            events.append(monitor.process(msg))

    # Compile results
    if not events:
        return {"error": "Not enough messages for analysis"}

    # Regime distribution
    regimes = [e.regime.value for e in events]
    regime_dist = {}
    for r in set(regimes):
        regime_dist[r] = regimes.count(r) / len(regimes)

    # Alerts
    alerts = [e for e in events if e.alert]

    # Trajectory
    trajectory = np.array([e.coordinates for e in events])

    # Metrics over time
    legibility_series = [e.legibility for e in events]
    velocity_series = [e.velocity for e in events]

    return {
        "total_messages": len(messages),
        "analyzed_messages": len(events),
        "regime_distribution": regime_dist,
        "alert_count": len(alerts),
        "alerts": [a.to_dict() for a in alerts],
        "mean_legibility": np.mean(legibility_series),
        "legibility_trend": legibility_series[-1] - legibility_series[0] if len(legibility_series) > 1 else 0,
        "mean_velocity": np.mean(velocity_series),
        "trajectory_length": np.sum([np.linalg.norm(trajectory[i+1] - trajectory[i])
                                      for i in range(len(trajectory)-1)]) if len(trajectory) > 1 else 0,
        "final_regime": events[-1].regime.value if events else None,
        "final_legibility": events[-1].legibility if events else None,
    }
